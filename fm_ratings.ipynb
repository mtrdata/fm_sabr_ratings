{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p0EFLSqvImY"
      },
      "source": [
        "# **Import**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zyzcd7zfPy-x",
        "outputId": "5e484b65-99d4-49f6-962f-39157bea97bc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_theme(style=\"darkgrid\")\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('***') # Fill in the path to the folder where the data is stored"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z86MS4I_2I8c"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "RI9FMq9cR3yf",
        "outputId": "78c639c9-2ae2-48fb-e1b2-1866cec35e1a"
      },
      "outputs": [],
      "source": [
        "def clean_dataframe(df):\n",
        "    # Fill NaN values with '0' in the df\n",
        "    df.fillna('0', inplace=True)\n",
        "\n",
        "    # Apply encoding fix to specified columns. This is to handle names or clubs with accents or special characters\n",
        "    encoding_columns = ['Name', 'Club']\n",
        "    for column in encoding_columns:\n",
        "        df[column] = df[column].apply(lambda x: try_encoding_fix(x) if isinstance(x, str) else x)\n",
        "\n",
        "    # Convert specified columns to string\n",
        "    columns_to_string = ['Name', 'Best Pos', 'Club', 'Division']\n",
        "    df[columns_to_string] = df[columns_to_string].astype('string')\n",
        "\n",
        "    # Define columns to convert to numbers and clean non-numeric characters\n",
        "    columns_to_numbers = [\n",
        "        'Tck/90', 'Shot/90', 'ShT/90', 'Shots Outside Box/90', 'Shts Blckd/90',\n",
        "        'Pr passes/90', 'Pres C/90', 'Pres A/90', 'Poss Won/90', 'Poss Lost/90',\n",
        "        'OP-KP/90', 'OP-Cr %', 'NP-xG/90', 'K Tck/90', 'K Ps/90', 'K Hdrs/90',\n",
        "        'Int/90', 'Hdr %', 'Gls/90', 'xG/90', 'xA/90', 'Drb/90', 'Cr C/A', 'Clr/90',\n",
        "        'Ch C/90', 'Blk/90', 'Asts/90', 'Aer A/90', 'Av Rat'\n",
        "    ]\n",
        "\n",
        "    # Clean and convert columns to numbers\n",
        "    df[columns_to_numbers] = df[columns_to_numbers].apply(lambda x: x.str.replace('-', '').str.replace('[^0-9.-]', '', regex=True).replace('', np.nan).astype(float).fillna(0))\n",
        "\n",
        "    # Process 'Mins' separately to convert to integer\n",
        "    df['Mins'] = df['Mins'].str.replace('-', '').str.replace('[^0-9]', '', regex=True).replace('', '0').astype(int)\n",
        "\n",
        "    # Drop Inf column that is not needed but is automatically created via the in-game view\n",
        "    df.drop(['Inf'], axis=1, inplace=True, errors='ignore')\n",
        "\n",
        "    # Function to group positions\n",
        "    def group_position(value):\n",
        "        position_map = {\n",
        "            'GK': 'Goalkeeper', 'D (R)': 'Full Back', 'D (L)': 'Full Back', 'D (C)': 'Centre Back',\n",
        "            'WB (R)': 'Wing Back', 'WB (L)': 'Wing Back', 'DM': 'Defensive Midfielder',\n",
        "            'M (R)': 'Winger', 'M (L)': 'Winger', 'M (C)': 'Central Midfielder',\n",
        "            'AM (R)': 'Wide Attacking Midfielder', 'AM (L)': 'Wide Attacking Midfielder',\n",
        "            'AM (C)': 'Central Attacking Midfielder', 'ST (C)': 'Striker'\n",
        "        }\n",
        "        return position_map.get(value, 'Unknown')\n",
        "\n",
        "    # Apply the function to the 'Best Pos' column\n",
        "    df['Best Pos'] = df['Best Pos'].apply(group_position)\n",
        "\n",
        "    # Rename columns for clearer column names\n",
        "    new_column_names = {\n",
        "        'Best Pos': 'Position', 'Av Rat': 'Average Rating', 'Mins': 'Minutes Played',\n",
        "        'Aer A/90': 'Aerial Challenges Attempted per 90', 'Asts/90': 'Assists per 90',\n",
        "        'Blk/90': 'Blocks per 90', 'Ch C/90': 'Chances Created per 90', 'Clr/90': 'Clearances per 90',\n",
        "        'Cr C/A': 'Cross Completion %', 'Drb/90': 'Dribbles per 90', 'xA/90': 'Expected Assists per 90',\n",
        "        'xG/90': 'Expected Goals per 90', 'Gls/90': 'Goals per 90', 'Hdr %': 'Headers Won %',\n",
        "        'Int/90': 'Interceptions per 90', 'K Hdrs/90': 'Key Headers per 90', 'K Ps/90': 'Key Passes per 90',\n",
        "        'K Tck/90': 'Key Tackles per 90', 'NP-xG/90': 'Non-Penalty xG per 90', 'OP-Cr %': 'Open-Play Cross Completion %',\n",
        "        'OP-KP/90': 'Open-Play Key Passes per 90', 'Poss Lost/90': 'Possession Lost per 90',\n",
        "        'Poss Won/90': 'Possession Won per 90', 'Pres A/90': 'Pressures Attempted per 90',\n",
        "        'Pres C/90': 'Pressures Completed per 90', 'Pr passes/90': 'Progressive Passes per 90',\n",
        "        'Shts Blckd/90': 'Shots Blocked per 90', 'Shots Outside Box/90': 'Shots Outside Box per 90',\n",
        "        'ShT/90': 'Shots on Target per 90', 'Shot/90': 'Shots per 90', 'Tck/90': 'Tackles Won per 90'\n",
        "    }\n",
        "    df.rename(columns=new_column_names, inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def try_encoding_fix(value):\n",
        "    try:\n",
        "        return value.encode('latin1').decode('utf-8')\n",
        "    except UnicodeDecodeError:\n",
        "        try:\n",
        "            return value.encode('windows-1252').decode('utf-8')\n",
        "        except UnicodeDecodeError:\n",
        "            return value\n",
        "\n",
        "# Adding a season column to the df based on the file name\n",
        "def add_season_column(df, file_name):\n",
        "    season_year = file_name\n",
        "    df['Season'] = season_year\n",
        "    return df\n",
        "\n",
        "# Function to convert HTML files to CSV files, clean the data, and add a 'Season' column\n",
        "def convert_html_to_csv_with_cleaning(start_year, end_year):\n",
        "    for year in range(start_year, end_year + 1):\n",
        "        html_file_name = f'{year}.html'\n",
        "        try:\n",
        "            tables = pd.read_html(html_file_name)\n",
        "            df = tables[0]\n",
        "\n",
        "            # Clean the df\n",
        "            df_cleaned = clean_dataframe(df)\n",
        "\n",
        "            # Add the 'Season' column using the year as the season identifier\n",
        "            df_with_season = add_season_column(df_cleaned, str(year))\n",
        "\n",
        "            csv_file_name = f'season_{year}.csv'\n",
        "            df_with_season.to_csv(csv_file_name, index=False)\n",
        "            print(f'Converted {html_file_name} to {csv_file_name} with cleaning and added season')\n",
        "        except Exception as e:\n",
        "            print(f'Failed to process {html_file_name}: {e}')\n",
        "\n",
        "# Call the function to convert and clean HTML files from 2024.html to 2038.html, adding the 'Season' column\n",
        "convert_html_to_csv_with_cleaning(2024, 2038)\n",
        "\n",
        "dfs = []\n",
        "\n",
        "for year in range(2024, 2039):  # 2039 is exclusive, so it goes up to 2038\n",
        "    file_name = f'season_{year}.csv'\n",
        "    df = pd.read_csv(file_name)\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all the dataframes into one final dataframe\n",
        "final_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "path_in_drive = '***' # Fill in the path to the folder where the data is stored\n",
        "\n",
        "final_df.to_csv(path_in_drive, index=False)\n",
        "\n",
        "print('All seasons concatenated into one CSV file.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPRYCEql2Rr-"
      },
      "source": [
        "# **Positional DF's**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Divide the main df into positional df to be used in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cysfYU-jxuBX"
      },
      "outputs": [],
      "source": [
        "# Identify all unique positions\n",
        "unique_positions = final_df['Position'].unique()\n",
        "\n",
        "# Dictionary to store dfs divided by position but only include players with more than 900 minutes played\n",
        "dfs_by_position = {}\n",
        "\n",
        "for position in unique_positions:\n",
        "    # Filter final_df for each position and for Minutes Played > 900 then store in the dictionary. Helps keep ratings more accurate\n",
        "    dfs_by_position[position] = final_df[(final_df['Position'] == position) & (final_df['Minutes Played'] > 900)]\n",
        "\n",
        "# Assuming your Google Drive is mounted and dfs_by_position is ready\n",
        "for position, df in dfs_by_position.items():\n",
        "    # Define the path in Google Drive where you want to save the CSV\n",
        "    path_in_drive = f'***/{position}.csv' # Fill in the path to the folder where the data is stored\n",
        "\n",
        "    # Save the DataFrame to a CSV file in the specified path\n",
        "    df.to_csv(path_in_drive, index=False)\n",
        "\n",
        "    print(f'{position}s with more than 900 minutes played saved to Google Drive.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFWgAdci2VlR"
      },
      "source": [
        "# **Model Preperation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Final preperation of the data for the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODIx35Zfz58n"
      },
      "outputs": [],
      "source": [
        "# Function to double check & filter players with more than 900 minutes played\n",
        "def filter_players(df):\n",
        "    return df.query(\"`Minutes Played` > 900\")\n",
        "\n",
        "# Load the divided dfs back in from the CSV files saved to the Drive\n",
        "full_backs = pd.read_csv('***/Full Back.csv')\n",
        "wing_backs = pd.read_csv('***/Wing Back.csv')\n",
        "centre_backs = pd.read_csv('***/Centre Back.csv')\n",
        "central_attacking_midfielders = pd.read_csv('***/Central Attacking Midfielder.csv')\n",
        "strikers = pd.read_csv('***/Striker.csv')\n",
        "defensive_midfielders = pd.read_csv('***/Defensive Midfielder.csv')\n",
        "central_midfielders = pd.read_csv('***/Central Midfielder.csv')\n",
        "wide_attacking_midfielders = pd.read_csv('***/Wide Attacking Midfielder.csv')\n",
        "wingers = pd.read_csv('***/Winger.csv')\n",
        "goalkeepers = pd.read_csv('***/Goalkeeper.csv')\n",
        "\n",
        "# Apply the filter_players function to each DataFrame\n",
        "full_backs_filtered = filter_players(full_backs)\n",
        "wing_backs_filtered = filter_players(wing_backs)\n",
        "centre_backs_filtered = filter_players(centre_backs)\n",
        "central_attacking_midfielders_filtered = filter_players(central_attacking_midfielders)\n",
        "strikers_filtered = filter_players(strikers)\n",
        "defensive_midfielders_filtered = filter_players(defensive_midfielders)\n",
        "central_midfielders_filtered = filter_players(central_midfielders)\n",
        "wide_attacking_midfielders_filtered = filter_players(wide_attacking_midfielders)\n",
        "wingers_filtered = filter_players(wingers)\n",
        "goalkeepers_filtered = filter_players(goalkeepers)\n",
        "\n",
        "# Columns to keep for the model\n",
        "columns_to_keep = [\n",
        "        'Aerial Challenges Attempted per 90',\n",
        "        'Assists per 90',\n",
        "        'Blocks per 90',\n",
        "        'Chances Created per 90',\n",
        "        'Clearances per 90',\n",
        "        'Cross Completion %',\n",
        "        'Dribbles per 90',\n",
        "        'Expected Assists per 90',\n",
        "        'Expected Goals per 90',\n",
        "        'Goals per 90',\n",
        "        'Headers Won %',\n",
        "        'Interceptions per 90',\n",
        "        'Key Headers per 90',\n",
        "        'Key Passes per 90',\n",
        "        'Key Tackles per 90',\n",
        "        'Non-Penalty xG per 90',\n",
        "        'Open-Play Cross Completion %',\n",
        "        'Open-Play Key Passes per 90',\n",
        "        'Possession Lost per 90',\n",
        "        'Possession Won per 90',\n",
        "        'Pressures Attempted per 90',\n",
        "        'Pressures Completed per 90',\n",
        "        'Progressive Passes per 90',\n",
        "        'Shots Blocked per 90',\n",
        "        'Shots Outside Box per 90',\n",
        "        'Shots on Target per 90',\n",
        "        'Shots per 90',\n",
        "        'Tackles Won per 90',\n",
        "        'Average Rating'\n",
        "    ]\n",
        "\n",
        "full_backs_model = full_backs_filtered[columns_to_keep]\n",
        "wing_backs_model = wing_backs_filtered[columns_to_keep]\n",
        "centre_backs_model = centre_backs_filtered[columns_to_keep]\n",
        "central_attacking_midfielders_model = central_attacking_midfielders_filtered[columns_to_keep]\n",
        "strikers_model = strikers_filtered[columns_to_keep]\n",
        "defensive_midfielders_model = defensive_midfielders_filtered[columns_to_keep]\n",
        "central_midfielders_model = central_midfielders_filtered[columns_to_keep]  # Corrected\n",
        "wide_attacking_midfielders_model = wide_attacking_midfielders_filtered[columns_to_keep]\n",
        "wingers_model = wingers_filtered[columns_to_keep]\n",
        "goalkeepers_model = goalkeepers_filtered[columns_to_keep]\n",
        "\n",
        "# Save the position specifc dfs for the model as CSV files to the specified Drive path\n",
        "full_backs_model.to_csv('***/full_backs_model.csv', index=False)\n",
        "wing_backs_model.to_csv('***/wing_backs_model.csv', index=False)\n",
        "centre_backs_model.to_csv('***/centre_backs_model.csv', index=False)\n",
        "central_attacking_midfielders_model.to_csv('***/central_attacking_midfielders_model.csv', index=False)\n",
        "strikers_model.to_csv('***/strikers_model.csv', index=False)\n",
        "defensive_midfielders_model.to_csv('***/defensive_midfielders_model.csv', index=False)\n",
        "central_midfielders_model.to_csv('***/central_midfielders_model.csv', index=False)\n",
        "wide_attacking_midfielders_model.to_csv('***/wide_attacking_midfielders_model.csv', index=False)\n",
        "wingers_model.to_csv('***/wingers_model.csv', index=False)\n",
        "goalkeepers_model.to_csv('***/goalkeepers_model.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model & R2 Scores**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FeatureImportanceModel:\n",
        "    def __init__(self, name, dataframe, target_column, importance_threshold):\n",
        "        self.name = name\n",
        "        self.dataframe = dataframe.copy()\n",
        "        self.target_column = target_column\n",
        "        self.importance_threshold = importance_threshold\n",
        "        self.model = LinearRegression()\n",
        "        self.selected_features = None\n",
        "        self.importance_df = None\n",
        "        self.new_importance_df = None\n",
        "\n",
        "    # Function to precprocess the data\n",
        "    def preprocess_data(self):\n",
        "        X = self.dataframe.drop(self.target_column, axis=1)\n",
        "        y = self.dataframe[self.target_column]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Impute missing values with the mean and scale the data. Fail safe in case of missing values missed in the cleaning process\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_train_imputed = imputer.fit_transform(X_train)\n",
        "        X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "        # Scale the data using StandardScaler\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "        X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "        return X_train_scaled, X_test_scaled, y_train, y_test, X.columns\n",
        "\n",
        "    # Function to train the initial model and print the R-Squared score for each poisition\n",
        "    def train_initial_model(self):\n",
        "        X_train_scaled, X_test_scaled, y_train, y_test, feature_names = self.preprocess_data()\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "        y_pred = self.model.predict(X_test_scaled)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f'{self.name} - Initial R-Squared:', r2)\n",
        "\n",
        "        # Get the feature importances using the absolute value of the coefficients\n",
        "        feature_importances = np.abs(self.model.coef_)\n",
        "        self.importance_df = pd.DataFrame({\n",
        "            'Feature': feature_names,\n",
        "            'Importance': feature_importances\n",
        "        }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Function to select important features based on the importance threshold as established by feature importance\n",
        "    def select_important_features(self):\n",
        "        self.selected_features = self.importance_df[self.importance_df['Importance'] > self.importance_threshold]['Feature'].tolist()\n",
        "\n",
        "    # Function to train the model now with the selected features and print the R-Squared score\n",
        "    def train_selected_model(self):\n",
        "        X = self.dataframe[self.selected_features]\n",
        "        y = self.dataframe[self.target_column]\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Impute missing values with the mean and scale the data. Fail safe in case of missing values missed in the cleaning process\n",
        "        imputer = SimpleImputer(strategy='mean')\n",
        "        X_train_imputed = imputer.fit_transform(X_train)\n",
        "        X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "        # Scale the data using StandardScaler\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "        X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "        self.model.fit(X_train_scaled, y_train)\n",
        "        y_pred = self.model.predict(X_test_scaled)\n",
        "        r2 = r2_score(y_test, y_pred)\n",
        "        print(f'\\n{self.name} - R-Squared with Selected Features:', r2)\n",
        "\n",
        "        new_feature_importances = np.abs(self.model.coef_)\n",
        "        self.new_importance_df = pd.DataFrame({\n",
        "            'Feature': self.selected_features,\n",
        "            'Importance': new_feature_importances\n",
        "        }).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Function to run the model\n",
        "    def run(self):\n",
        "        self.train_initial_model()\n",
        "        self.select_important_features()\n",
        "        self.train_selected_model()\n",
        "\n",
        "    # Function to save the feature importance dfs to a CSV file for future use\n",
        "    def save_feature_importance(self, filename):\n",
        "        path = f'***/{filename}' # Fill in the path to the folder where the data is stored\n",
        "        self.new_importance_df.to_csv(path, index=False)\n",
        "        print(f\"Saved feature importance for {self.name} to {filename}\")\n",
        "\n",
        "# Load the dfs for each position\n",
        "centre_backs = pd.read_csv('***/centre_backs_model.csv')\n",
        "full_backs = pd.read_csv('***/full_backs_model.csv')\n",
        "wing_backs = pd.read_csv('***/wing_backs_model.csv')\n",
        "defensive_midfielders = pd.read_csv('***/defensive_midfielders_model.csv')\n",
        "central_midfielders = pd.read_csv('***/central_midfielders_model.csv')\n",
        "central_attacking_midfielders = pd.read_csv('***/central_attacking_midfielders_model.csv')\n",
        "wingers = pd.read_csv('***/wingers_model.csv')\n",
        "wide_attacking_midfielders = pd.read_csv('***/wide_attacking_midfielders_model.csv')\n",
        "strikers = pd.read_csv('***/strikers_model.csv')\n",
        "\n",
        "# Define the models with different thresholds. These were determined through trial and error\n",
        "centre_backs_model = FeatureImportanceModel('Centre Backs', centre_backs, 'Average Rating', 0.0018)\n",
        "full_backs_model = FeatureImportanceModel('Full Backs', full_backs, 'Average Rating', 0.002)\n",
        "wing_backs_model = FeatureImportanceModel('Wing Backs', wing_backs, 'Average Rating', 0.0015)\n",
        "defensive_midfielders_model = FeatureImportanceModel('Defensive Midfielders', defensive_midfielders, 'Average Rating', 0.0025)\n",
        "central_midfielders_model = FeatureImportanceModel('Central Midfielders', central_midfielders, 'Average Rating', 0.002)\n",
        "central_attacking_midfielders_model = FeatureImportanceModel('Central Attacking Midfielders', central_attacking_midfielders, 'Average Rating', 0.0022)\n",
        "wingers_model = FeatureImportanceModel('Wingers', wingers, 'Average Rating', 0.0018)\n",
        "wide_attacking_midfielders_model = FeatureImportanceModel('Wide Attacking Midfielders', wide_attacking_midfielders, 'Average Rating', 0.002)\n",
        "strikers_model = FeatureImportanceModel('Strikers', strikers, 'Average Rating', 0.002)\n",
        "\n",
        "# Run the models\n",
        "centre_backs_model.run()\n",
        "full_backs_model.run()\n",
        "wing_backs_model.run()\n",
        "defensive_midfielders_model.run()\n",
        "central_midfielders_model.run()\n",
        "central_attacking_midfielders_model.run()\n",
        "wingers_model.run()\n",
        "wide_attacking_midfielders_model.run()\n",
        "strikers_model.run()\n",
        "\n",
        "# Save feature importance dfs to CSV files\n",
        "centre_backs_model.save_feature_importance('centre_backs_importance.csv')\n",
        "full_backs_model.save_feature_importance('full_backs_importance.csv')\n",
        "wing_backs_model.save_feature_importance('wing_backs_importance.csv')\n",
        "defensive_midfielders_model.save_feature_importance('defensive_midfielders_importance.csv')\n",
        "central_midfielders_model.save_feature_importance('central_midfielders_importance.csv')\n",
        "central_attacking_midfielders_model.save_feature_importance('central_attacking_midfielders_importance.csv')\n",
        "wingers_model.save_feature_importance('wingers_importance.csv')\n",
        "wide_attacking_midfielders_model.save_feature_importance('wide_attacking_midfielders_importance.csv')\n",
        "strikers_model.save_feature_importance('strikers_importance.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Adjusted Rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data\n",
        "df = pd.read_csv('***/final_df.csv')\n",
        "\n",
        "# Filter out Goalkeepers and Unknown positions from the dataframe\n",
        "df = df[~df['Position'].isin(['Goalkeeper', 'Unknown'])]\n",
        "\n",
        "# Read the world DataFrame from an HTML file\n",
        "world = pd.read_html('world.html')[0]\n",
        "\n",
        "# Create the division_ranks dictionary based on the order of the leagues in the 'world' DataFrame\n",
        "division_ranks = {league: rank + 1 for rank, league in enumerate(world['Name'])}\n",
        "print(\"Division Ranks:\")\n",
        "for division, rank in division_ranks.items():\n",
        "    print(f\"{division}: {rank}\")\n",
        "\n",
        "def calculate_division_weight(rank):\n",
        "    \"\"\"\n",
        "    Calculate the division weight based on the division rank.\n",
        "    Lower rank numbers (top of the list) represent better divisions and should have higher weights.\n",
        "    \"\"\"\n",
        "    return 1 / (rank ** 0.5)  # Using square root to reduce the impact of rank differences\n",
        "\n",
        "# Function to calculate ratings for a given season and position\n",
        "def calculate_rating(df, position_model, season, position):\n",
        "    # Filter the DataFrame for the given season and position\n",
        "    season_df = df[(df['Season'] == season) & (df['Position'] == position)]\n",
        "\n",
        "    if season_df.empty:\n",
        "        print(f\"No data for {position} in {season}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Get the feature importances\n",
        "    importances = position_model.new_importance_df.set_index('Feature')['Importance']\n",
        "\n",
        "    # Calculate the maximum minutes for the season\n",
        "    max_minutes = season_df['Minutes Played'].max()\n",
        "\n",
        "    # Calculate the weighted sum of metrics\n",
        "    weighted_sum = season_df[importances.index].mul(importances, axis=1).sum(axis=1)\n",
        "\n",
        "    # Calculate the raw rating\n",
        "    season_df['Raw Rating'] = weighted_sum\n",
        "\n",
        "    # Adjust rating based on minutes played\n",
        "    season_df['Minutes Factor'] = season_df['Minutes Played'] / max_minutes\n",
        "    season_df['Adjusted Rating'] = season_df['Raw Rating'] * season_df['Minutes Factor']\n",
        "\n",
        "    # Calculate division weight\n",
        "    season_df['Division Weight'] = season_df['Division'].map(division_ranks).apply(calculate_division_weight)\n",
        "\n",
        "    # Apply division weight to the adjusted rating\n",
        "    season_df['Weighted Rating'] = season_df['Adjusted Rating'] * season_df['Division Weight']\n",
        "\n",
        "    # Scale the Weighted Rating to 0-10 (this is now our SABR Rating)\n",
        "    min_rating = season_df['Weighted Rating'].min()\n",
        "    max_rating = season_df['Weighted Rating'].max()\n",
        "    season_df['SABR Rating'] = ((season_df['Weighted Rating'] - min_rating) / (max_rating - min_rating) * 10).round(2)\n",
        "\n",
        "    # Sort by SABR Rating in descending order\n",
        "    season_df = season_df.sort_values('SABR Rating', ascending=False)\n",
        "\n",
        "    # Structure of the final df\n",
        "    return season_df[['UID','Name', 'Position', 'Age', 'Club', 'Division', 'Minutes Played',\n",
        "        'Aerial Challenges Attempted per 90',\n",
        "        'Assists per 90',\n",
        "        'Blocks per 90',\n",
        "        'Chances Created per 90',\n",
        "        'Clearances per 90',\n",
        "        'Cross Completion %',\n",
        "        'Dribbles per 90',\n",
        "        'Expected Assists per 90',\n",
        "        'Expected Goals per 90',\n",
        "        'Goals per 90',\n",
        "        'Headers Won %',\n",
        "        'Interceptions per 90',\n",
        "        'Key Headers per 90',\n",
        "        'Key Passes per 90',\n",
        "        'Key Tackles per 90',\n",
        "        'Non-Penalty xG per 90',\n",
        "        'Open-Play Cross Completion %',\n",
        "        'Open-Play Key Passes per 90',\n",
        "        'Possession Lost per 90',\n",
        "        'Possession Won per 90',\n",
        "        'Pressures Attempted per 90',\n",
        "        'Pressures Completed per 90',\n",
        "        'Progressive Passes per 90',\n",
        "        'Shots Blocked per 90',\n",
        "        'Shots Outside Box per 90',\n",
        "        'Shots on Target per 90',\n",
        "        'Shots per 90',\n",
        "        'Tackles Won per 90',\n",
        "        'Season',\n",
        "        'Average Rating',\n",
        "        'SABR Rating']]\n",
        "\n",
        "# List of seasons, positions, and divisions in the df\n",
        "seasons = sorted(df['Season'].unique())\n",
        "positions = sorted(df['Position'].unique())\n",
        "divisions = list(world['Name'])\n",
        "\n",
        "# Dictionary to map position names to their respective models\n",
        "position_models = {\n",
        "    'Centre Back': centre_backs_model,\n",
        "    'Full Back': full_backs_model,\n",
        "    'Wing Back': wing_backs_model,\n",
        "    'Defensive Midfielder': defensive_midfielders_model,\n",
        "    'Central Midfielder': central_midfielders_model,\n",
        "    'Central Attacking Midfielder': central_attacking_midfielders_model,\n",
        "    'Winger': wingers_model,\n",
        "    'Wide Attacking Midfielder': wide_attacking_midfielders_model,\n",
        "    'Striker': strikers_model\n",
        "}\n",
        "\n",
        "# Check if all positions in the data have corresponding models\n",
        "missing_models = set(positions) - set(position_models.keys())\n",
        "if missing_models:\n",
        "    print(f\"Warning: The following positions do not have corresponding models: {missing_models}\")\n",
        "\n",
        "# Calculate ratings for each season, position, and division\n",
        "all_ratings = []\n",
        "\n",
        "for season in seasons:\n",
        "    for position in positions:\n",
        "        if position in position_models:\n",
        "            print(f\"Calculating ratings for {position} in season {season}\")\n",
        "            ratings = calculate_rating(df, position_models[position], season, position)\n",
        "            if not ratings.empty:\n",
        "                print(f\"Calculated ratings for {len(ratings)} players in {position} for season {season}\")\n",
        "                all_ratings.append(ratings)\n",
        "            else:\n",
        "                print(f\"No ratings calculated for {position} in season {season}\")\n",
        "        else:\n",
        "            print(f\"No model found for {position}\")\n",
        "\n",
        "print(f\"Total number of rating calculations: {len(all_ratings)}\")\n",
        "\n",
        "# Combine all ratings into a single dataframe\n",
        "if all_ratings:\n",
        "    final_ratings = pd.concat(all_ratings, ignore_index=True)\n",
        "\n",
        "    # Calculate the mean of 'Average Rating' and 'SABR Rating' for each UID\n",
        "    mean_ratings = final_ratings.groupby('UID').agg({\n",
        "        'Average Rating': 'mean',\n",
        "        'SABR Rating': 'mean',\n",
        "        'Name': 'first',  # Keep the first occurrence of the name\n",
        "        'Position': lambda x: ', '.join(set(x)),  # Join unique positions\n",
        "        'Age': 'max',  # Use the maximum age\n",
        "        'Club': 'last',  # Use the last club\n",
        "        'Division': 'last',  # Use the last division\n",
        "        'Minutes Played': 'sum',  # Sum up all minutes played\n",
        "        'Season': 'nunique'  # Count unique seasons\n",
        "    }).reset_index()\n",
        "\n",
        "    # Rename the columns for more clarity\n",
        "    mean_ratings = mean_ratings.rename(columns={\n",
        "        'Average Rating': 'Adjusted Rating',\n",
        "        'SABR Rating': 'Adjusted SABR Rating',\n",
        "        'Season': 'Total Number Of Seasons Stored'\n",
        "    })\n",
        "\n",
        "    # Merge the mean ratings back to the final_ratings dataframe\n",
        "    final_ratings = final_ratings.merge(mean_ratings[['UID', 'Adjusted Rating', 'Adjusted SABR Rating', 'Total Number Of Seasons Stored']], on='UID')\n",
        "\n",
        "    # Round the ratings to two decimal points\n",
        "    final_ratings['SABR Rating'] = final_ratings['SABR Rating'].round(2)\n",
        "    final_ratings['Adjusted Rating'] = final_ratings['Adjusted Rating'].round(2)\n",
        "    final_ratings['Adjusted SABR Rating'] = final_ratings['Adjusted SABR Rating'].round(2)\n",
        "\n",
        "    # Add the difference column\n",
        "    final_ratings['Rating Difference'] = (final_ratings['Adjusted SABR Rating'] - final_ratings['Adjusted Rating']).round(2)\n",
        "\n",
        "    # Rearrange the columns in the desired order\n",
        "    column_order = [\n",
        "        'UID', 'Name', 'Position', 'Age', 'Club', 'Division', 'Minutes Played',\n",
        "        'Season', 'Total Number Of Seasons Stored', 'Average Rating', 'SABR Rating',\n",
        "        'Adjusted Rating', 'Adjusted SABR Rating', 'Rating Difference',\n",
        "        'Aerial Challenges Attempted per 90', 'Assists per 90', 'Blocks per 90',\n",
        "        'Chances Created per 90', 'Clearances per 90', 'Cross Completion %',\n",
        "        'Dribbles per 90', 'Expected Assists per 90', 'Expected Goals per 90',\n",
        "        'Goals per 90', 'Headers Won %', 'Interceptions per 90', 'Key Headers per 90',\n",
        "        'Key Passes per 90', 'Key Tackles per 90', 'Non-Penalty xG per 90',\n",
        "        'Open-Play Cross Completion %', 'Open-Play Key Passes per 90',\n",
        "        'Possession Lost per 90', 'Possession Won per 90', 'Pressures Attempted per 90',\n",
        "        'Pressures Completed per 90', 'Progressive Passes per 90', 'Shots Blocked per 90',\n",
        "        'Shots Outside Box per 90', 'Shots on Target per 90', 'Shots per 90',\n",
        "        'Tackles Won per 90'\n",
        "    ]\n",
        "\n",
        "    final_ratings = final_ratings.reindex(columns=column_order)\n",
        "\n",
        "    # Save the final ratings to a CSV file\n",
        "    final_ratings.to_csv('***/player_ratings.csv', index=False)\n",
        "\n",
        "    print(\"Ratings calculation complete. Results saved to CSV.\")\n",
        "else:\n",
        "    print(\"No ratings were calculated.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
